{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# 多行输出\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据与预处理参考 [yooChooseRec.ipynb](./yooChooseRec.ipynb)\n",
    "\n",
    "这里解决用户在某个session中会发生购买行为，预测用户购买什么东西"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc\n",
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from torch import nn, optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool\n",
    "from torch_geometric.data import Data, InMemoryDataset, DataLoader\n",
    "from torch_geometric.nn import GraphConv, TopKPooling, GatedGraphConv, SAGEConv, SGConv\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('../data/yoochoose-data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicks = pd.read_csv(root / 'clicks_pro.csv', encoding='utf-8', low_memory=False)\n",
    "# buys = pd.read_csv(root / 'buys_pro.csv', encoding='utf-8', low_memory=False)\n",
    "clicks = pd.read_csv(root / 'clicks_pro_100m.csv', encoding='utf-8', low_memory=False)\n",
    "buys = pd.read_csv(root / 'buys_pro_100m.csv', encoding='utf-8', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id    1000000\n",
       "timestamp     5552990\n",
       "item_id         37196\n",
       "category          263\n",
       "label               2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "session_id     84817\n",
       "timestamp     216577\n",
       "item_id        12373\n",
       "price            511\n",
       "quantity          22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicks.nunique()\n",
    "buys.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2014-04-06T11:26:24.127Z</td>\n",
       "      <td>6926</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2014-04-06T11:28:54.654Z</td>\n",
       "      <td>6926</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2014-04-06T11:29:13.479Z</td>\n",
       "      <td>6926</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2014-04-01T10:09:01.362Z</td>\n",
       "      <td>7116</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>2014-04-01T10:11:14.773Z</td>\n",
       "      <td>8100</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                 timestamp  item_id  category  label\n",
       "0           9  2014-04-06T11:26:24.127Z     6926         0  False\n",
       "1           9  2014-04-06T11:28:54.654Z     6926         0  False\n",
       "2           9  2014-04-06T11:29:13.479Z     6926         0  False\n",
       "3          14  2014-04-01T10:09:01.362Z     7116         0  False\n",
       "4          14  2014-04-01T10:11:14.773Z     8100         0  False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>140806</td>\n",
       "      <td>2014-04-07T09:22:28.132Z</td>\n",
       "      <td>14011</td>\n",
       "      <td>523</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140806</td>\n",
       "      <td>2014-04-07T09:22:28.176Z</td>\n",
       "      <td>8219</td>\n",
       "      <td>1046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140806</td>\n",
       "      <td>2014-04-07T09:22:28.219Z</td>\n",
       "      <td>8001</td>\n",
       "      <td>837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140806</td>\n",
       "      <td>2014-04-07T09:22:28.268Z</td>\n",
       "      <td>25054</td>\n",
       "      <td>1151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140806</td>\n",
       "      <td>2014-04-07T09:22:28.280Z</td>\n",
       "      <td>7211</td>\n",
       "      <td>1046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                 timestamp  item_id  price  quantity\n",
       "0      140806  2014-04-07T09:22:28.132Z    14011    523         1\n",
       "1      140806  2014-04-07T09:22:28.176Z     8219   1046         1\n",
       "2      140806  2014-04-07T09:22:28.219Z     8001    837         1\n",
       "3      140806  2014-04-07T09:22:28.268Z    25054   1151         1\n",
       "4      140806  2014-04-07T09:22:28.280Z     7211   1046         1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicks.head()\n",
    "buys.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 使用最大值而不是 nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37196"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clicks.item_id.max() + 1\n",
    "clicks.category.max() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 购买力字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_item_dict = dict(buys.groupby('session_id')['item_id'].apply(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root/'buy_item_dict.pkl',  'wb') as f:\n",
    "    pickle.dump(buy_item_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YooChooseDatasetNode(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['buy_binary100m.pt']\n",
    "        # return ['buy_binary.pt']    # for whole dataset\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        data_list = []\n",
    "        # clicks= pd.read_csv(root / 'clicks_pro.csv', encoding='utf-8', low_memory=False)  # 使用全部数据\n",
    "        clicks = pd.read_csv(root / 'clicks_pro_100m.csv', encoding='utf-8', low_memory=False)    # 使用部分数据\n",
    "        with open(root / 'buy_item_dict.pkl', 'rb') as f:\n",
    "            buy_item_dict = pickle.load(f)\n",
    "\n",
    "        # process by session_id\n",
    "        grouped = iter(clicks.groupby('session_id'))\n",
    "        lens = clicks.session_id.unique().shape[0]\n",
    "\n",
    "        # buys 不需要常驻内存, 并且使用动态加载\n",
    "        del clicks\n",
    "\n",
    "        for session_id, group in tqdm(grouped, total=lens):\n",
    "            # 重新编码，作为节点的顺序\n",
    "            item_lb = LabelEncoder()\n",
    "            sess_item_id = item_lb.fit_transform(group.item_id)\n",
    "\n",
    "            # 重建索引\n",
    "            group = group.reset_index(drop=True)\n",
    "            group['sess_item_id'] = sess_item_id\n",
    "\n",
    "            # 节点的初始特征\n",
    "            # 重复的浏览记录当做一次记录\n",
    "            # 使用 [item id, category] 作为节点特征\n",
    "            node_features = group.loc[group.session_id ==\n",
    "                                      session_id, ['sess_item_id', 'item_id', 'category']].sort_values('sess_item_id')[[\n",
    "                                          'item_id', 'category'\n",
    "                                      ]].drop_duplicates().values\n",
    "            node_features = torch.LongTensor(node_features).unsqueeze(1)\n",
    "\n",
    "            # 序列访问的顺序\n",
    "            source_nodes = group.sess_item_id.values[:-1]\n",
    "            target_nodes = group.sess_item_id.values[1:]\n",
    "            edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "            # 构造 x, y\n",
    "            x = node_features\n",
    "\n",
    "            if session_id in buy_item_dict:\n",
    "                positive_indices = item_lb.transform(buy_item_dict[session_id])\n",
    "                # one-hot 编码\n",
    "                label = np.zeros(len(node_features))\n",
    "                label[positive_indices] = 1\n",
    "            else:\n",
    "                label = [0] * len(node_features)\n",
    "\n",
    "            y = torch.FloatTensor(label)\n",
    "\n",
    "            data = Data(x=x, edge_index=edge_index, y=y)\n",
    "            data_list.append(data)\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = YooChooseDatasetNode(root)\n",
    "dataset = dataset.shuffle()\n",
    "train_dataset, val_dataset, test_dataset = dataset[:800000], dataset[800000:900000], dataset[900000:]\n",
    "len_train = 800000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 1024\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37196, 263)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items = clicks.item_id.max() +1\n",
    "num_categories = clicks.category.max()+1\n",
    "num_items , num_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del clicks, buys, dataset, train_dataset, val_dataset, test_dataset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetNode(nn.Module):\n",
    "    def __init__(self, num_items, num_categories, emb_sz=128, p=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.item_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=emb_sz)\n",
    "        self.category_embedding = nn.Embedding(num_embeddings=num_categories, embedding_dim=emb_sz)\n",
    "\n",
    "        self.conv1 = GraphConv(emb_sz * 2, 128)\n",
    "        self.pool1 = TopKPooling(128, ratio=0.9)\n",
    "\n",
    "        self.conv2 = GraphConv(128, 128)\n",
    "        self.pool2 = TopKPooling(128, ratio=0.9)\n",
    "\n",
    "        self.conv3 = GraphConv(128, 128)\n",
    "        self.pool3 = TopKPooling(128, ratio=0.9)\n",
    "\n",
    "        self.fc1 = nn.Sequential(nn.Linear(256, 256), nn.ReLU())\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "\n",
    "        self.drop = p\n",
    "        self.ac = nn.ReLU()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        item_id, category = x[:, :, 0], x[:, :, 1]\n",
    "\n",
    "        emb_item = self.item_embedding(item_id).squeeze(1)\n",
    "        emb_category = self.category_embedding(category).squeeze(1)\n",
    "\n",
    "        x = torch.cat([emb_item, emb_category], dim=1)\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch, *_ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x, edge_index, _, batch, *_ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x, edge_index, _, batch, *_ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([global_max_pool(x, batch), global_mean_pool(x, batch)], dim=1)\n",
    "\n",
    "        x = x1 + x2 + x3\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.dropout(x, p=self.drop, training=self.training)\n",
    "        x = self.ac(x)\n",
    "\n",
    "        outputs = []\n",
    "        for i in range(x.size(0)):\n",
    "            output = torch.matmul(emb_item[data.batch == i], x[i, :])\n",
    "            outputs.append(output)\n",
    "\n",
    "        x = torch.cat(outputs, dim=0)\n",
    "        x = torch.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        label = data.y.to(device)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        loss_all += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "    return loss_all / len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "    labels = []\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data).detach().cpu().numpy()\n",
    "        label = data.y.detach().cpu().numpy()\n",
    "        predictions.append(pred)\n",
    "        labels.append(label)\n",
    "\n",
    "    predictions = np.hstack(predictions)\n",
    "    labels = np.hstack(labels)\n",
    "    return roc_auc_score(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda: 0' if torch.cuda.is_available() else 'cpu')\n",
    "model = NetNode(37197,  264).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 0.36615, Train Auc: 0.66282, Val Auc: 0.65518, Test Auc: 0.65176\n",
      "Epoch: 001, Loss: 0.25901, Train Auc: 0.72887, Val Auc: 0.70953, Test Auc: 0.70834\n",
      "Epoch: 002, Loss: 0.23043, Train Auc: 0.76399, Val Auc: 0.73564, Test Auc: 0.73676\n",
      "Epoch: 003, Loss: 0.21250, Train Auc: 0.79811, Val Auc: 0.75792, Test Auc: 0.75902\n",
      "Epoch: 004, Loss: 0.19966, Train Auc: 0.81499, Val Auc: 0.76711, Test Auc: 0.76695\n",
      "Epoch: 005, Loss: 0.19048, Train Auc: 0.83226, Val Auc: 0.77382, Test Auc: 0.77470\n",
      "Epoch: 006, Loss: 0.18290, Train Auc: 0.84464, Val Auc: 0.77752, Test Auc: 0.77727\n",
      "Epoch: 007, Loss: 0.17586, Train Auc: 0.85812, Val Auc: 0.77747, Test Auc: 0.77786\n",
      "Epoch: 008, Loss: 0.17064, Train Auc: 0.86737, Val Auc: 0.77547, Test Auc: 0.77624\n",
      "Epoch: 009, Loss: 0.16548, Train Auc: 0.87729, Val Auc: 0.77351, Test Auc: 0.77247\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    loss = train()\n",
    "    train_acc = evaluate(train_loader)\n",
    "    val_acc = evaluate(val_loader)    \n",
    "    test_acc = evaluate(test_loader)\n",
    "    print('Epoch: {:03d}, Loss: {:.5f}, Train Auc: {:.5f}, Val Auc: {:.5f}, Test Auc: {:.5f}'.\n",
    "          format(epoch, loss, train_acc, val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
